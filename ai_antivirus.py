#!/usr/bin/env python3
"""
üöÄ ULTIMATE AI ANTIVIRUS v3.0
Enhanced AI-powered security agent with modular design, real-time dashboard, and comprehensive testing capabilities.
"""

import os
import sys
import time
import shutil
import logging
import pickle
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import signal
import argparse
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import colorama
from colorama import Fore, Back, Style
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table
from rich.panel import Panel
from rich.live import Live
from rich.layout import Layout
import threading
from typing import Dict, List, Optional, Tuple

# Initialize colorama and rich for enhanced output
colorama.init(autoreset=True)
console = Console()

# ============================================================================
# CONSTANTS SECTION
# ============================================================================

# Threat levels with emojis and colors
THREAT_LEVELS = {
    'CRITICAL': {'emoji': 'üî•', 'color': Fore.RED, 'score_range': (0.8, 1.0)},
    'HIGH_RISK': {'emoji': '‚ö†Ô∏è', 'color': Fore.MAGENTA, 'score_range': (0.6, 0.8)},
    'SUSPICIOUS': {'emoji': 'üü°', 'color': Fore.YELLOW, 'score_range': (0.3, 0.6)},
    'SAFE': {'emoji': '‚úÖ', 'color': Fore.GREEN, 'score_range': (0.0, 0.3)}
}

# Suspicious file extensions
SUSPICIOUS_EXTENSIONS = {
    '.exe', '.bat', '.vbs', '.scr', '.ps1', '.cmd', '.com', 
    '.pif', '.reg', '.js', '.jar', '.msi', '.dll', '.sys'
}

# Dashboard refresh rate (seconds)
DASHBOARD_REFRESH_RATE = 2

# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def get_threat_level(score: float) -> Dict:
    """Get threat level based on AI score."""
    for level, config in THREAT_LEVELS.items():
        min_score, max_score = config['score_range']
        if min_score <= score <= max_score:
            return {
                'level': level,
                'emoji': config['emoji'],
                'color': config['color'],
                'score': score
            }
    return THREAT_LEVELS['SAFE']

def format_file_size(size_bytes: int) -> str:
    """Format file size in human-readable format."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} TB"

def create_timestamp() -> str:
    """Create timestamp string for logging."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")

# ============================================================================
# ENHANCED AI ANTIVIRUS CLASS
# ============================================================================

class UltimateAIAntivirus:
    def __init__(self, monitor_path: str, quarantine_enabled: bool = True, 
                 model_path: str = "model/model.pkl", gui_mode: bool = False):
        """
        Initialize the Ultimate AI Antivirus system.
        
        Args:
            monitor_path: Path to monitor for suspicious files
            quarantine_enabled: Whether to move suspicious files to quarantine
            model_path: Path to the trained ML model
            gui_mode: Whether to run in GUI mode
        """
        self.monitor_path = Path(monitor_path).resolve()
        self.quarantine_enabled = quarantine_enabled
        self.model_path = Path(model_path)
        self.gui_mode = gui_mode
        
        # Statistics tracking
        self.stats = {
            'files_scanned': 0,
            'threats_found': 0,
            'quarantined': 0,
            'ai_detections': 0,
            'extension_detections': 0,
            'both_detections': 0,
            'start_time': datetime.now(),
            'last_scan_time': None
        }
        
        # Create necessary directories
        self.logs_dir = Path("logs")
        self.quarantine_dir = Path("quarantine")
        self.model_dir = Path("model")
        self._create_directories()
        
        # Setup logging first
        self._setup_logging()
        
        # Load or train the AI model
        self.model = self._load_or_train_model()
        
        # Initialize watchdog observer
        self.observer = Observer()
        self.event_handler = UltimateAIAntivirusEventHandler(self)
        
        # Dashboard components
        self.dashboard_active = False
        self.dashboard_thread = None
        
        self._print_startup_info()
    
    def _create_directories(self):
        """Create logs, quarantine, and model directories if they don't exist."""
        self.logs_dir.mkdir(exist_ok=True)
        if self.quarantine_enabled:
            self.quarantine_dir.mkdir(exist_ok=True)
        self.model_dir.mkdir(exist_ok=True)
    
    def _setup_logging(self):
        """Setup enhanced logging configuration."""
        timestamp = create_timestamp()
        log_file = self.logs_dir / f"ultimate_antivirus_{timestamp}.log"
        
        # Create formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # File handler
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        
        # Console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        
        # Setup logger
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # Log startup
        self.logger.info("üöÄ Ultimate AI Antivirus v3.0 Started")
        self.logger.info(f"üìÅ Monitoring path: {self.monitor_path}")
        self.logger.info(f"üõ°Ô∏è Quarantine enabled: {self.quarantine_enabled}")
    
    def _print_startup_info(self):
        """Print enhanced startup information."""
        console.print(Panel.fit(
            "[bold cyan]üöÄ ULTIMATE AI ANTIVIRUS v3.0[/bold cyan]\n"
            "[green]Enhanced Security Agent with AI Integration[/green]",
            border_style="cyan"
        ))
        
        console.print(f"[cyan]üìÅ Monitoring:[/cyan] {self.monitor_path}")
        console.print(f"[yellow]üõ°Ô∏è Quarantine:[/yellow] {'Enabled' if self.quarantine_enabled else 'Disabled'}")
        console.print(f"[magenta]üß† AI Model:[/magenta] {'Loaded' if self.model else 'Training...'}")
        console.print(f"[blue]‚ö†Ô∏è Suspicious extensions:[/blue] {', '.join(sorted(SUSPICIOUS_EXTENSIONS))}")
        console.print(f"[cyan]üëÅÔ∏è File monitoring started[/cyan]")
        console.print(f"[yellow]Press Ctrl+C to stop monitoring[/yellow]\n")
    
    def _load_or_train_model(self):
        """Load existing model or train a new one."""
        if self.model_path.exists():
            try:
                with open(self.model_path, 'rb') as f:
                    model = pickle.load(f)
                self.logger.info("üß† AI model loaded successfully")
                return model
            except Exception as e:
                self.logger.warning(f"‚ùå Failed to load model: {e}")
        
        # Train new model if loading fails
        self.logger.info("üß† Training new AI model...")
        return self._train_model()
    
    def _create_training_data(self):
        """Create enhanced training data for the AI model."""
        np.random.seed(42)  # For reproducible results
        
        # Generate dummy data
        data = []
        
        # Safe files (mostly small, common extensions)
        safe_extensions = ['.txt', '.pdf', '.jpg', '.png', '.mp3', '.mp4', '.doc', '.xls', '.zip', '.rar']
        for _ in range(150):
            ext = np.random.choice(safe_extensions)
            size = np.random.randint(1, 2000)  # 1-2000 KB
            data.append({
                'file_extension': ext,
                'file_size_kb': size,
                'is_malicious': 0
            })
        
        # Suspicious files (mostly large, dangerous extensions)
        suspicious_extensions = ['.exe', '.bat', '.vbs', '.scr', '.ps1', '.cmd', '.com', '.pif', '.reg']
        for _ in range(120):
            ext = np.random.choice(suspicious_extensions)
            size = np.random.randint(100, 10000)  # 100-10000 KB
            data.append({
                'file_extension': ext,
                'file_size_kb': size,
                'is_malicious': 1
            })
        
        # Some safe files with suspicious extensions (false positives)
        for _ in range(30):
            ext = np.random.choice(suspicious_extensions)
            size = np.random.randint(1, 100)  # Small size
            data.append({
                'file_extension': ext,
                'file_size_kb': size,
                'is_malicious': 0
            })
        
        # Some large safe files
        for _ in range(30):
            ext = np.random.choice(safe_extensions)
            size = np.random.randint(2000, 50000)  # Large size
            data.append({
                'file_extension': ext,
                'file_size_kb': size,
                'is_malicious': 0
            })
        
        df = pd.DataFrame(data)
        
        # Save training data
        training_data_path = self.model_dir / "training_data.csv"
        df.to_csv(training_data_path, index=False)
        self.logger.info(f"üìä Training data created: {training_data_path}")
        
        return df
    
    def _train_model(self):
        """Train the enhanced Random Forest model."""
        # Create training data
        df = self._create_training_data()
        
        # Prepare features
        # Convert extensions to numerical features (one-hot encoding)
        extension_dummies = pd.get_dummies(df['file_extension'], prefix='ext')
        
        # Combine features
        X = pd.concat([extension_dummies, df[['file_size_kb']]], axis=1)
        y = df['is_malicious']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Train model
        model = RandomForestClassifier(n_estimators=150, random_state=42, max_depth=10)
        model.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        self.logger.info(f"üß† Model trained with accuracy: {accuracy:.3f}")
        self.logger.info(f"üìä Classification Report:\n{classification_report(y_test, y_pred)}")
        
        # Save model
        with open(self.model_path, 'wb') as f:
            pickle.dump(model, f)
        
        self.logger.info(f"üíæ Model saved to: {self.model_path}")
        return model
    
    def _extract_features(self, file_path: Path) -> Optional[Dict]:
        """Extract enhanced features from a file for AI prediction."""
        try:
            # Get file stats
            stats = file_path.stat()
            file_size_kb = stats.st_size / 1024  # Convert to KB
            extension = file_path.suffix.lower()
            
            # Create feature vector
            features = {
                'file_size_kb': file_size_kb,
                'extension': extension,
                'file_name': file_path.name,
                'last_modified': datetime.fromtimestamp(stats.st_mtime)
            }
            
            return features
            
        except Exception as e:
            self.logger.error(f"‚ùå Error extracting features from {file_path}: {e}")
            return None
    
    def _predict_with_ai(self, features: Dict) -> Dict:
        """Use AI model to predict if file is malicious."""
        try:
            # Prepare features for model
            extension = features['extension']
            file_size_kb = features['file_size_kb']
            
            # Create feature vector (matching training data format)
            feature_vector = np.zeros(len(self.model.feature_names_in_))
            
            # Set file size
            size_idx = np.where(self.model.feature_names_in_ == 'file_size_kb')[0]
            if len(size_idx) > 0:
                feature_vector[size_idx[0]] = file_size_kb
            
            # Set extension (one-hot encoding)
            ext_prefix = 'ext_'
            for i, feature_name in enumerate(self.model.feature_names_in_):
                if feature_name.startswith(ext_prefix):
                    if feature_name == f'ext_{extension}':
                        feature_vector[i] = 1
            
            # Make prediction
            prediction = self.model.predict([feature_vector])[0]
            confidence = self.model.predict_proba([feature_vector])[0]
            
            return {
                'is_malicious': bool(prediction),
                'confidence': max(confidence),
                'prediction': prediction
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå AI prediction error: {e}")
            return {
                'is_malicious': False,
                'confidence': 0.0,
                'prediction': 0
            }
    
    def is_suspicious_by_extension(self, file_path: Path) -> bool:
        """Check if a file is suspicious based on its extension."""
        return file_path.suffix.lower() in SUSPICIOUS_EXTENSIONS
    
    def analyze_file(self, file_path: Path) -> Optional[Dict]:
        """Analyze a file using both traditional and AI methods."""
        if not file_path.exists():
            return None
        
        # Extract features
        features = self._extract_features(file_path)
        if not features:
            return None
        
        # Traditional extension-based detection
        extension_suspicious = self.is_suspicious_by_extension(file_path)
        
        # AI-based detection
        ai_result = self._predict_with_ai(features)
        
        # Combine both methods
        ai_suspicious = ai_result['is_malicious']
        confidence = ai_result['confidence']
        
        # Determine final result
        is_suspicious = extension_suspicious or ai_suspicious
        
        # Determine detection method
        if extension_suspicious and ai_suspicious:
            detection_method = "BOTH"
        elif extension_suspicious:
            detection_method = "EXTENSION"
        elif ai_suspicious:
            detection_method = "AI"
        else:
            detection_method = "SAFE"
        
        # Get threat level
        threat_info = get_threat_level(confidence)
        
        # Update statistics
        self.stats['files_scanned'] += 1
        if is_suspicious:
            self.stats['threats_found'] += 1
            if detection_method == "AI":
                self.stats['ai_detections'] += 1
            elif detection_method == "EXTENSION":
                self.stats['extension_detections'] += 1
            elif detection_method == "BOTH":
                self.stats['both_detections'] += 1
        
        self.stats['last_scan_time'] = datetime.now()
        
        return {
            'file_path': file_path,
            'is_suspicious': is_suspicious,
            'extension_suspicious': extension_suspicious,
            'ai_suspicious': ai_suspicious,
            'ai_confidence': confidence,
            'detection_method': detection_method,
            'file_size_kb': features['file_size_kb'],
            'extension': features['extension'],
            'threat_level': threat_info,
            'last_modified': features['last_modified']
        }
    
    def log_threat(self, analysis_result: Dict):
        """Log threat detection with enhanced information."""
        file_path = analysis_result['file_path']
        detection_method = analysis_result['detection_method']
        ai_confidence = analysis_result['ai_confidence']
        threat_level = analysis_result['threat_level']
        file_size = analysis_result['file_size_kb']
        
        # Log detailed information
        self.logger.warning(f"üö® THREAT DETECTED: {file_path}")
        self.logger.info(f"üìä File size: {file_size:.1f} KB")
        self.logger.info(f"üîç Detection method: {detection_method}")
        self.logger.info(f"üß† AI confidence: {ai_confidence:.2%}")
        self.logger.info(f"‚ö†Ô∏è Threat level: {threat_level['level']} {threat_level['emoji']}")
        self.logger.info(f"üïí Last modified: {analysis_result['last_modified']}")
        self.logger.info(f"üìÅ Extension: {analysis_result['extension']}")
    
    def quarantine_file(self, file_path: Path) -> Tuple[bool, Optional[Path]]:
        """Move a suspicious file to the quarantine folder."""
        try:
            if not self.quarantine_enabled:
                return False, None
            
            # Create quarantine filename with timestamp
            timestamp = create_timestamp()
            quarantine_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
            quarantine_path = self.quarantine_dir / quarantine_name
            
            # Move file to quarantine
            shutil.move(str(file_path), str(quarantine_path))
            self.stats['quarantined'] += 1
            return True, quarantine_path
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to quarantine {file_path}: {e}")
            return False, None
    
    def handle_suspicious_file(self, analysis_result: Dict):
        """Handle a detected suspicious file with enhanced display."""
        file_path = analysis_result['file_path']
        detection_method = analysis_result['detection_method']
        ai_confidence = analysis_result['ai_confidence']
        threat_level = analysis_result['threat_level']
        file_size = analysis_result['file_size_kb']
        
        # Log the threat
        self.log_threat(analysis_result)
        
        # Print colorful alert
        threat_color = threat_level['color']
        threat_emoji = threat_level['emoji']
        
        console.print(f"\n{threat_color}{threat_emoji} THREAT DETECTED! {threat_emoji}{Style.RESET_ALL}")
        console.print(f"[cyan]üìÅ File:[/cyan] {file_path}")
        console.print(f"[magenta]üîç Detection:[/magenta] {detection_method}")
        console.print(f"[green]üìä Size:[/green] {format_file_size(int(file_size * 1024))}")
        console.print(f"[blue]üß† AI Confidence:[/blue] {ai_confidence:.2%}")
        console.print(f"[yellow]‚ö†Ô∏è Threat Level:[/yellow] {threat_level['level']} {threat_emoji}")
        
        # Try to quarantine the file
        if self.quarantine_enabled:
            success, quarantine_path = self.quarantine_file(file_path)
            if success:
                console.print(f"[red]üö´ Quarantined:[/red] {quarantine_path}")
                self.logger.info(f"üö´ Quarantined: {file_path} -> {quarantine_path}")
            else:
                console.print(f"[red]‚ùå Failed to quarantine[/red]")
        else:
            console.print(f"[yellow]‚ö†Ô∏è File left in place (quarantine disabled)[/yellow]")
            self.logger.info(f"‚ö†Ô∏è File left in place (quarantine disabled)")
    
    def scan_directory(self, show_progress: bool = True):
        """Scan the monitored directory for existing suspicious files."""
        self.logger.info(f"üîç Scanning directory: {self.monitor_path}")
        
        # Get all files
        files = list(self.monitor_path.rglob("*"))
        files = [f for f in files if f.is_file()]
        
        suspicious_count = 0
        
        if show_progress:
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console
            ) as progress:
                task = progress.add_task("Scanning files...", total=len(files))
                
                for file_path in files:
                    analysis_result = self.analyze_file(file_path)
                    if analysis_result and analysis_result['is_suspicious']:
                        suspicious_count += 1
                        self.handle_suspicious_file(analysis_result)
                    progress.advance(task)
        else:
            for file_path in files:
                analysis_result = self.analyze_file(file_path)
                if analysis_result and analysis_result['is_suspicious']:
                    suspicious_count += 1
                    self.handle_suspicious_file(analysis_result)
        
        self.logger.info(f"‚úÖ Initial scan complete. Found {suspicious_count} suspicious files.")
        console.print(f"[green]‚úÖ Scan complete. Found {suspicious_count} suspicious files.[/green]")
    
    def create_dashboard(self) -> Layout:
        """Create a real-time dashboard."""
        layout = Layout()
        
        # Header
        header = Panel(
            "[bold cyan]üöÄ ULTIMATE AI ANTIVIRUS v3.0 - LIVE DASHBOARD[/bold cyan]",
            border_style="cyan"
        )
        
        # Statistics table
        stats_table = Table(title="üìä Real-Time Statistics")
        stats_table.add_column("Metric", style="cyan")
        stats_table.add_column("Value", style="green")
        stats_table.add_column("Details", style="yellow")
        
        uptime = datetime.now() - self.stats['start_time']
        files_per_second = self.stats['files_scanned'] / max(uptime.total_seconds(), 1)
        
        stats_table.add_row("Files Scanned", str(self.stats['files_scanned']), f"{files_per_second:.1f}/sec")
        stats_table.add_row("Threats Found", str(self.stats['threats_found']), f"{self.stats['threats_found']/max(self.stats['files_scanned'], 1)*100:.1f}%")
        stats_table.add_row("Quarantined", str(self.stats['quarantined']), "Protected")
        stats_table.add_row("AI Detections", str(self.stats['ai_detections']), "Machine Learning")
        stats_table.add_row("Extension Detections", str(self.stats['extension_detections']), "Rule-based")
        stats_table.add_row("Both Detections", str(self.stats['both_detections']), "AI + Rules")
        stats_table.add_row("Uptime", str(uptime).split('.')[0], "Active monitoring")
        
        # Layout
        layout.split_column(
            Layout(header, size=3),
            Layout(stats_table, size=10)
        )
        
        return layout
    
    def start_dashboard(self):
        """Start the real-time dashboard."""
        self.dashboard_active = True
        
        def dashboard_loop():
            with Live(self.create_dashboard(), refresh_per_second=1, console=console) as live:
                while self.dashboard_active:
                    live.update(self.create_dashboard())
                    time.sleep(DASHBOARD_REFRESH_RATE)
        
        self.dashboard_thread = threading.Thread(target=dashboard_loop, daemon=True)
        self.dashboard_thread.start()
    
    def stop_dashboard(self):
        """Stop the real-time dashboard."""
        self.dashboard_active = False
        if self.dashboard_thread:
            self.dashboard_thread.join()
    
    def start_monitoring(self):
        """Start monitoring the directory for new files."""
        try:
            # Start dashboard if not in GUI mode
            if not self.gui_mode:
                self.start_dashboard()
            
            # Schedule the observer
            self.observer.schedule(
                self.event_handler, 
                str(self.monitor_path), 
                recursive=True
            )
            self.observer.start()
            
            # Keep the script running
            while True:
                time.sleep(1)
                
        except KeyboardInterrupt:
            self.stop_monitoring()
        except Exception as e:
            self.logger.error(f"‚ùå Error during monitoring: {e}")
            self.stop_monitoring()
    
    def stop_monitoring(self):
        """Stop the file monitoring."""
        self.stop_dashboard()
        self.observer.stop()
        self.observer.join()
        console.print(f"\n[yellow]üõë AI Antivirus monitoring stopped[/yellow]")
        self.logger.info("üõë AI Antivirus monitoring stopped")
    
    def get_system_tray_status(self) -> Dict:
        """Get system tray status (placeholder for future pystray integration)."""
        return {
            'active': True,
            'threats_detected': self.stats['threats_found'],
            'files_scanned': self.stats['files_scanned'],
            'quarantined': self.stats['quarantined']
        }


class UltimateAIAntivirusEventHandler(FileSystemEventHandler):
    """Enhanced event handler for file system events."""
    
    def __init__(self, antivirus):
        self.antivirus = antivirus
    
    def on_created(self, event):
        """Handle file creation events."""
        if event.is_directory:
            return
        
        file_path = Path(event.src_path)
        # Small delay to ensure file is fully written
        time.sleep(0.5)
        if file_path.exists():
            analysis_result = self.antivirus.analyze_file(file_path)
            if analysis_result and analysis_result['is_suspicious']:
                self.antivirus.handle_suspicious_file(analysis_result)
    
    def on_moved(self, event):
        """Handle file move events."""
        if event.is_directory:
            return
        
        file_path = Path(event.dest_path)
        analysis_result = self.antivirus.analyze_file(file_path)
        if analysis_result and analysis_result['is_suspicious']:
            self.antivirus.handle_suspicious_file(analysis_result)


def signal_handler(signum, frame):
    """Handle Ctrl+C gracefully."""
    console.print(f"\n[yellow]üõë Received interrupt signal. Shutting down...[/yellow]")
    sys.exit(0)


def create_gui_placeholder():
    """Create GUI placeholder for future Tkinter integration."""
    console.print("[cyan]üñ•Ô∏è GUI mode placeholder - Future feature[/cyan]")
    console.print("[yellow]GUI integration planned for future versions[/yellow]")


def main():
    """Main function to run the Ultimate AI antivirus."""
    parser = argparse.ArgumentParser(
        description="üöÄ Ultimate AI Antivirus v3.0 - Enhanced Security Agent",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python ai_antivirus.py --path Downloads --scan-only
  python ai_antivirus.py --path /home/user --retrain
  python ai_antivirus.py --demo --gui
        """
    )
    
    parser.add_argument(
        "--path", 
        default="Downloads", 
        help="Path to monitor (default: Downloads)"
    )
    parser.add_argument(
        "--no-quarantine", 
        action="store_true", 
        help="Disable quarantine functionality"
    )
    parser.add_argument(
        "--scan-only", 
        action="store_true", 
        help="Only scan existing files, don't monitor for new ones"
    )
    parser.add_argument(
        "--retrain", 
        action="store_true", 
        help="Retrain the AI model"
    )
    parser.add_argument(
        "--demo", 
        action="store_true", 
        help="Run in demo mode with sample files"
    )
    parser.add_argument(
        "--gui", 
        action="store_true", 
        help="Enable GUI mode (placeholder for future)"
    )
    
    args = parser.parse_args()
    
    # Setup signal handler for graceful shutdown
    signal.signal(signal.SIGINT, signal_handler)
    
    # Initialize antivirus
    antivirus = UltimateAIAntivirus(
        monitor_path=args.path,
        quarantine_enabled=not args.no_quarantine,
        gui_mode=args.gui
    )
    
    # Retrain model if requested
    if args.retrain:
        console.print(f"[cyan]üîÑ Retraining AI model...[/cyan]")
        antivirus.model = antivirus._train_model()
    
    # Demo mode
    if args.demo:
        console.print(f"[cyan]üéÆ Demo mode activated[/cyan]")
        # Demo functionality would go here
    
    # GUI mode
    if args.gui:
        create_gui_placeholder()
    
    # Perform initial scan
    antivirus.scan_directory()
    
    # Start monitoring if not scan-only mode
    if not args.scan_only:
        antivirus.start_monitoring()
    else:
        console.print(f"[green]‚úÖ Scan complete. Exiting...[/green]")


if __name__ == "__main__":
    main()