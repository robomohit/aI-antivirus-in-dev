#!/usr/bin/env python3
"""
Download Real Malware from MalwareBazaar
Download thousands of real malware samples and extract features
"""

import os
import sys
import json
import requests
import hashlib
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import logging
from colorama import init, Fore, Style
import time
import zipfile
import shutil

# Initialize colorama
init()

class MalwareBazaarDownloader:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://mb-api.abuse.ch/api/v1/"
        self.download_dir = "malware_samples"
        self.features_dir = "malware_features"
        
        # Create directories
        Path(self.download_dir).mkdir(exist_ok=True)
        Path(self.features_dir).mkdir(exist_ok=True)
        
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('malware_download.log'),
                logging.StreamHandler()
            ]
        )
    
    def get_malware_list(self, limit=1000, days_back=30):
        """Get list of malware samples from MalwareBazaar."""
        print(f"{Fore.CYAN}🔄 Fetching malware list from MalwareBazaar...")
        
        # Query parameters
        data = {
            "query": "get_recent",
            "selector": "100",  # Get recent samples
            "time": str(days_back)  # Days back
        }
        
        try:
            response = requests.post(self.base_url, data=data)
            response.raise_for_status()
            
            result = response.json()
            
            if result.get("query_status") == "ok":
                samples = result.get("data", [])
                print(f"{Fore.GREEN}✅ Found {len(samples)} malware samples")
                return samples
            else:
                print(f"{Fore.RED}❌ Query failed: {result.get('query_status')}")
                return []
                
        except Exception as e:
            print(f"{Fore.RED}❌ Error fetching malware list: {e}")
            return []
    
    def download_sample(self, sample_info):
        """Download a single malware sample."""
        try:
            sha256_hash = sample_info.get("sha256_hash")
            file_type = sample_info.get("file_type", "unknown")
            file_name = sample_info.get("file_name", f"{sha256_hash}.bin")
            
            # Skip if already downloaded
            sample_path = Path(self.download_dir) / f"{sha256_hash}.bin"
            if sample_path.exists():
                return True, sample_path
            
            # Download sample
            data = {
                "query": "get_file",
                "sha256_hash": sha256_hash
            }
            
            response = requests.post(self.base_url, data=data)
            response.raise_for_status()
            
            # Save sample
            with open(sample_path, 'wb') as f:
                f.write(response.content)
            
            return True, sample_path
            
        except Exception as e:
            logging.error(f"Error downloading {sha256_hash}: {e}")
            return False, None
    
    def extract_features_from_file(self, file_path):
        """Extract features from a malware file."""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            # Basic file info
            file_size = len(data)
            
            # Calculate features (same as old model)
            features = {
                'file_size': file_size,
                'entropy': self.calculate_entropy(data),
                'strings_count': self.count_strings(data),
                'avg_string_length': self.calculate_avg_string_length(data),
                'printable_ratio': self.calculate_printable_ratio(data),
                'histogram_regularity': self.calculate_histogram_regularity(data),
                'entropy_consistency': self.calculate_entropy_consistency(data)
            }
            
            return features
            
        except Exception as e:
            logging.error(f"Error extracting features from {file_path}: {e}")
            return None
    
    def calculate_entropy(self, data):
        """Calculate Shannon entropy."""
        if not data:
            return 0
        byte_counts = {}
        for byte in data:
            byte_counts[byte] = byte_counts.get(byte, 0) + 1
        
        entropy = 0
        data_len = len(data)
        for count in byte_counts.values():
            probability = count / data_len
            if probability > 0:
                entropy -= probability * np.log2(probability)
        return entropy
    
    def count_strings(self, data):
        """Count printable strings."""
        try:
            strings = data.decode('utf-8', errors='ignore').split('\x00')
            return len([s for s in strings if len(s) > 3])
        except:
            return 0
    
    def calculate_avg_string_length(self, data):
        """Calculate average string length."""
        try:
            strings = data.decode('utf-8', errors='ignore').split('\x00')
            valid_strings = [s for s in strings if len(s) > 3]
            return np.mean([len(s) for s in valid_strings]) if valid_strings else 0
        except:
            return 0
    
    def calculate_printable_ratio(self, data):
        """Calculate ratio of printable characters."""
        try:
            printable = sum(1 for b in data if 32 <= b <= 126)
            return printable / len(data) if data else 0
        except:
            return 0
    
    def calculate_histogram_regularity(self, data):
        """Calculate histogram regularity."""
        if not data:
            return 0
        histogram = np.histogram(data, bins=256, range=(0, 256))[0]
        return np.std(histogram) / np.mean(histogram) if np.mean(histogram) > 0 else 0
    
    def calculate_entropy_consistency(self, data):
        """Calculate entropy consistency."""
        if len(data) < 1024:
            return 0
        chunks = [data[i:i+1024] for i in range(0, len(data), 1024)]
        entropies = [self.calculate_entropy(chunk) for chunk in chunks]
        return np.std(entropies)
    
    def download_and_extract_batch(self, batch_size=100):
        """Download a batch of malware samples and extract features."""
        print(f"{Fore.CYAN}🔄 Downloading batch of {batch_size} malware samples...")
        
        # Get malware list
        samples = self.get_malware_list(limit=batch_size)
        
        if not samples:
            print(f"{Fore.RED}❌ No samples found")
            return []
        
        features_list = []
        downloaded_count = 0
        
        for i, sample in enumerate(samples):
            try:
                print(f"{Fore.CYAN}📥 Downloading {i+1}/{len(samples)}: {sample.get('file_name', 'unknown')}")
                
                # Download sample
                success, file_path = self.download_sample(sample)
                
                if success and file_path:
                    downloaded_count += 1
                    
                    # Extract features
                    features = self.extract_features_from_file(file_path)
                    
                    if features:
                        # Add metadata
                        features['sha256_hash'] = sample.get('sha256_hash')
                        features['file_name'] = sample.get('file_name', 'unknown')
                        features['file_type'] = sample.get('file_type', 'unknown')
                        features['first_seen'] = sample.get('first_seen', 'unknown')
                        features['label'] = 1  # Malware
                        
                        features_list.append(features)
                        
                        print(f"{Fore.GREEN}✅ Extracted features from {file_path.name}")
                    
                    # Rate limiting
                    time.sleep(1)
                
            except Exception as e:
                logging.error(f"Error processing sample {i}: {e}")
                continue
        
        print(f"{Fore.GREEN}✅ Downloaded {downloaded_count} samples")
        print(f"{Fore.GREEN}✅ Extracted features from {len(features_list)} samples")
        
        return features_list
    
    def create_benign_dataset(self, count=1000):
        """Create a dataset of benign files for comparison."""
        print(f"{Fore.CYAN}🔄 Creating benign dataset...")
        
        benign_features = []
        
        # Generate benign file patterns
        benign_patterns = [
            # Text files
            ("This is a normal text document with regular content.", 0.9, 3.2),
            ('{"config": "normal", "safe": true, "data": "legitimate"}', 0.95, 3.5),
            ("# Python script\nimport os\nprint('Hello World')", 0.8, 4.1),
            
            # Binary patterns (legitimate executables)
            ("MZ\x90\x00\x03\x00\x00\x00\x04\x00\x00\x00\xFF\xFF", 0.4, 5.8),
            ("\x7fELF\x02\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00", 0.3, 6.2),
        ]
        
        for i in range(count):
            # Randomly select a pattern
            pattern, printable_ratio, entropy = benign_patterns[i % len(benign_patterns)]
            
            # Generate file content
            if isinstance(pattern, str):
                content = pattern.encode('utf-8')
                # Add some variation
                content += b'\x00' * np.random.randint(0, 100)
            else:
                content = pattern
            
            # Calculate features
            features = {
                'file_size': len(content),
                'entropy': entropy + np.random.uniform(-0.5, 0.5),
                'strings_count': np.random.randint(5, 50),
                'avg_string_length': np.random.uniform(5.0, 15.0),
                'printable_ratio': printable_ratio + np.random.uniform(-0.1, 0.1),
                'histogram_regularity': np.random.uniform(0.1, 0.3),
                'entropy_consistency': np.random.uniform(0.1, 0.5),
                'sha256_hash': f"benign_{i:06d}",
                'file_name': f"benign_file_{i}.txt",
                'file_type': 'text',
                'first_seen': datetime.now().isoformat(),
                'label': 0  # Benign
            }
            
            benign_features.append(features)
        
        print(f"{Fore.GREEN}✅ Created {len(benign_features)} benign samples")
        return benign_features
    
    def save_dataset(self, malware_features, benign_features, filename=None):
        """Save the complete dataset."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"malware_bazaar_dataset_{timestamp}.csv"
        
        # Combine datasets
        all_features = malware_features + benign_features
        
        # Convert to DataFrame
        df = pd.DataFrame(all_features)
        
        # Save to CSV
        csv_path = Path(self.features_dir) / filename
        df.to_csv(csv_path, index=False)
        
        print(f"{Fore.GREEN}✅ Dataset saved: {csv_path}")
        print(f"{Fore.CYAN}📊 Total samples: {len(df)}")
        print(f"{Fore.CYAN}📊 Malware samples: {len(malware_features)}")
        print(f"{Fore.CYAN}📊 Benign samples: {len(benign_features)}")
        
        return csv_path
    
    def run_download_process(self, malware_batches=5, samples_per_batch=200):
        """Run the complete download and feature extraction process."""
        print(f"{Fore.CYAN}🛡️  MALWARE BAZAAR DOWNLOAD PROCESS")
        print(f"{Fore.CYAN}{'='*50}")
        
        all_malware_features = []
        
        # Download multiple batches
        for batch in range(malware_batches):
            print(f"\n{Fore.YELLOW}📦 Batch {batch + 1}/{malware_batches}")
            print(f"{Fore.YELLOW}{'-'*30}")
            
            batch_features = self.download_and_extract_batch(samples_per_batch)
            all_malware_features.extend(batch_features)
            
            # Wait between batches
            if batch < malware_batches - 1:
                print(f"{Fore.CYAN}⏳ Waiting 30 seconds before next batch...")
                time.sleep(30)
        
        # Create benign dataset
        print(f"\n{Fore.YELLOW}📁 Creating benign dataset...")
        benign_features = self.create_benign_dataset(count=len(all_malware_features))
        
        # Save complete dataset
        print(f"\n{Fore.YELLOW}💾 Saving complete dataset...")
        dataset_path = self.save_dataset(all_malware_features, benign_features)
        
        print(f"\n{Fore.GREEN}🎉 DOWNLOAD PROCESS COMPLETE!")
        print(f"{Fore.CYAN}📊 Total malware samples: {len(all_malware_features)}")
        print(f"{Fore.CYAN}📊 Total benign samples: {len(benign_features)}")
        print(f"{Fore.CYAN}📁 Dataset saved: {dataset_path}")
        
        return dataset_path

def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Download Malware from MalwareBazaar')
    parser.add_argument('--api-key', required=True, help='MalwareBazaar API key')
    parser.add_argument('--batches', type=int, default=5, help='Number of batches to download')
    parser.add_argument('--samples-per-batch', type=int, default=200, help='Samples per batch')
    
    args = parser.parse_args()
    
    print(f"{Fore.CYAN}🛡️  Starting MalwareBazaar Download...")
    
    downloader = MalwareBazaarDownloader(args.api_key)
    downloader.run_download_process(args.batches, args.samples_per_batch)

if __name__ == "__main__":
    main()